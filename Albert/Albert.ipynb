{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/anaconda3/envs/ML/lib/python3.8/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from datasets import Dataset, DatasetDict\n",
    "\n",
    "dataset_path = '/Users/rjaditya/Documents/NEU-SEM/Spring-2024/ML/LLM-vs-Human-Text-Detection/train_v2_drcat_02.csv'\n",
    "df = pd.read_csv(dataset_path, header = 0)\n",
    "\n",
    "### get the labels\n",
    "label = df['label']\n",
    "label = label.astype(\"int\")\n",
    "# df.drop(columns='label', axis = 1, inplace = True)\n",
    "df.drop(columns='RDizzl3_seven', axis = 1, inplace=True)\n",
    "df.drop(columns='prompt_name', axis = 1, inplace=True)\n",
    "df.drop(columns='source', axis = 1, inplace=True)\n",
    "df.dropna(subset=['text'], inplace=True)\n",
    "\n",
    "train_df, test_df = train_test_split(df, test_size=0.2, random_state=42, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>39024</th>\n",
       "      <td>Ummm... hey there!  So, like, I know it's kind...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16614</th>\n",
       "      <td>Dear Principal,\\n\\nAs you may know, many stude...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37944</th>\n",
       "      <td>The cafeteria at our school is an important re...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3563</th>\n",
       "      <td>Some schools require students to complete summ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31644</th>\n",
       "      <td>When considering the advantages and disadvanta...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    text  label\n",
       "39024  Ummm... hey there!  So, like, I know it's kind...      1\n",
       "16614  Dear Principal,\\n\\nAs you may know, many stude...      0\n",
       "37944  The cafeteria at our school is an important re...      1\n",
       "3563   Some schools require students to complete summ...      0\n",
       "31644  When considering the advantages and disadvanta...      1"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DatasetDict({\n",
      "    train: Dataset({\n",
      "        features: ['text', 'label', '__index_level_0__'],\n",
      "        num_rows: 35894\n",
      "    })\n",
      "    test: Dataset({\n",
      "        features: ['text', 'label', '__index_level_0__'],\n",
      "        num_rows: 8974\n",
      "    })\n",
      "})\n"
     ]
    }
   ],
   "source": [
    "# create a dataset object with train and test data.\n",
    "dataset = DatasetDict()\n",
    "dataset['train'] = Dataset.from_pandas(train_df)\n",
    "dataset['test'] = Dataset.from_pandas(test_df)\n",
    "print(dataset)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AlbertTokenizer, AlbertModel\n",
    "import torch\n",
    "\n",
    "### testing\n",
    "model = AlbertModel.from_pretrained(\"albert-base-v2\", num_labels = 2)\n",
    "tokenizer = AlbertTokenizer.from_pretrained(\"albert-base-v2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize_func(dataset):\n",
    "    return tokenizer(dataset['text'], padding = \"max_ength\", truncation = True)\n",
    "\n",
    "tokenized_datasets = dataset.map(tokenize_func, batched = True)\n",
    "train_dataset = tokenized_datasets[\"train\"].shuffle(seed=42)\n",
    "eval_dataset = tokenized_datasets[\"test\"].shuffle(seed=42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import Trainer, TrainingArguments\n",
    "import evaluate\n",
    "\n",
    "args = TrainingArguments(output_dir=\"LLMvHuman\", evaluation_strategy=\"epoch\")\n",
    "metric = evaluate.load('accuracy')\n",
    "\n",
    "def compute_metrics(eval_pred):\n",
    "    logits, labels = eval_pred\n",
    "    predictions = np.argmax(logits, axis=-1)\n",
    "    return metric.compute(predictions=predictions, references=labels)\n",
    "trainer = Trainer(\n",
    "    model,\n",
    "    args,\n",
    "    train_dataset=train_dataset,\n",
    "    eval_dataset=eval_dataset,\n",
    "    compute_metrics=compute_metrics\n",
    ")\n",
    "\n",
    "for epoch in range(2):\n",
    "    trainer.train()\n",
    "\n",
    "while torch.no_grad():\n",
    "    essay = \"\"\"\n",
    "            this is bla bla generated by bla bla. will my model bla bla should i find bla bla. Rombo bla bla adikuromo. Adippom.\n",
    "        \"\"\"\n",
    "    op = model()\n",
    "    prediction = F.softmax(op.logits, dim = 1)\n",
    "    labels = torch.argmax(prediction)\n",
    "    print(label)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ML",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
