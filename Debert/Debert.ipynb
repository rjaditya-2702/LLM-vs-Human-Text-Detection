{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e0c07908-13a1-4945-bb31-a3bcf56b0c82",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: datasets in ./.local/lib/python3.8/site-packages (2.18.0)\n",
      "Requirement already satisfied: numpy>=1.17 in /shared/centos7/anaconda3/2021.05/lib/python3.8/site-packages (from datasets) (1.20.1)\n",
      "Requirement already satisfied: pandas in /shared/centos7/anaconda3/2021.05/lib/python3.8/site-packages (from datasets) (1.2.4)\n",
      "Requirement already satisfied: xxhash in ./.local/lib/python3.8/site-packages (from datasets) (3.4.1)\n",
      "Requirement already satisfied: multiprocess in ./.local/lib/python3.8/site-packages (from datasets) (0.70.16)\n",
      "Requirement already satisfied: dill<0.3.9,>=0.3.0 in ./.local/lib/python3.8/site-packages (from datasets) (0.3.8)\n",
      "Requirement already satisfied: huggingface-hub>=0.19.4 in ./.local/lib/python3.8/site-packages (from datasets) (0.22.2)\n",
      "Requirement already satisfied: tqdm>=4.62.1 in ./.local/lib/python3.8/site-packages (from datasets) (4.66.2)\n",
      "Requirement already satisfied: pyarrow>=12.0.0 in ./.local/lib/python3.8/site-packages (from datasets) (15.0.2)\n",
      "Requirement already satisfied: fsspec[http]<=2024.2.0,>=2023.1.0 in ./.local/lib/python3.8/site-packages (from datasets) (2024.2.0)\n",
      "Requirement already satisfied: requests>=2.19.0 in /shared/centos7/anaconda3/2021.05/lib/python3.8/site-packages (from datasets) (2.25.1)\n",
      "Requirement already satisfied: aiohttp in ./.local/lib/python3.8/site-packages (from datasets) (3.9.3)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /shared/centos7/anaconda3/2021.05/lib/python3.8/site-packages (from datasets) (5.4.1)\n",
      "Requirement already satisfied: packaging in /shared/centos7/anaconda3/2021.05/lib/python3.8/site-packages (from datasets) (20.9)\n",
      "Requirement already satisfied: pyarrow-hotfix in ./.local/lib/python3.8/site-packages (from datasets) (0.6)\n",
      "Requirement already satisfied: filelock in /shared/centos7/anaconda3/2021.05/lib/python3.8/site-packages (from datasets) (3.0.12)\n",
      "Requirement already satisfied: async-timeout<5.0,>=4.0 in ./.local/lib/python3.8/site-packages (from aiohttp->datasets) (4.0.3)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in ./.local/lib/python3.8/site-packages (from aiohttp->datasets) (1.9.4)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in ./.local/lib/python3.8/site-packages (from aiohttp->datasets) (1.3.1)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in ./.local/lib/python3.8/site-packages (from aiohttp->datasets) (1.4.1)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in ./.local/lib/python3.8/site-packages (from aiohttp->datasets) (6.0.5)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /shared/centos7/anaconda3/2021.05/lib/python3.8/site-packages (from aiohttp->datasets) (20.3.0)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in ./.local/lib/python3.8/site-packages (from huggingface-hub>=0.19.4->datasets) (4.11.0)\n",
      "Requirement already satisfied: pyparsing>=2.0.2 in /shared/centos7/anaconda3/2021.05/lib/python3.8/site-packages (from packaging->datasets) (2.4.7)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /shared/centos7/anaconda3/2021.05/lib/python3.8/site-packages (from requests>=2.19.0->datasets) (1.26.4)\n",
      "Requirement already satisfied: chardet<5,>=3.0.2 in /shared/centos7/anaconda3/2021.05/lib/python3.8/site-packages (from requests>=2.19.0->datasets) (4.0.0)\n",
      "Requirement already satisfied: idna<3,>=2.5 in /shared/centos7/anaconda3/2021.05/lib/python3.8/site-packages (from requests>=2.19.0->datasets) (2.10)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /shared/centos7/anaconda3/2021.05/lib/python3.8/site-packages (from requests>=2.19.0->datasets) (2020.12.5)\n",
      "Requirement already satisfied: python-dateutil>=2.7.3 in /shared/centos7/anaconda3/2021.05/lib/python3.8/site-packages (from pandas->datasets) (2.8.1)\n",
      "Requirement already satisfied: pytz>=2017.3 in /shared/centos7/anaconda3/2021.05/lib/python3.8/site-packages (from pandas->datasets) (2021.1)\n",
      "Requirement already satisfied: six>=1.5 in /shared/centos7/anaconda3/2021.05/lib/python3.8/site-packages (from python-dateutil>=2.7.3->pandas->datasets) (1.15.0)\n",
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: accelerate in ./.local/lib/python3.8/site-packages (0.29.2)\n",
      "Requirement already satisfied: packaging>=20.0 in /shared/centos7/anaconda3/2021.05/lib/python3.8/site-packages (from accelerate) (20.9)\n",
      "Requirement already satisfied: numpy>=1.17 in /shared/centos7/anaconda3/2021.05/lib/python3.8/site-packages (from accelerate) (1.20.1)\n",
      "Requirement already satisfied: torch>=1.10.0 in ./.local/lib/python3.8/site-packages (from accelerate) (2.2.2)\n",
      "Requirement already satisfied: psutil in /shared/centos7/anaconda3/2021.05/lib/python3.8/site-packages (from accelerate) (5.8.0)\n",
      "Requirement already satisfied: pyyaml in /shared/centos7/anaconda3/2021.05/lib/python3.8/site-packages (from accelerate) (5.4.1)\n",
      "Requirement already satisfied: huggingface-hub in ./.local/lib/python3.8/site-packages (from accelerate) (0.22.2)\n",
      "Requirement already satisfied: safetensors>=0.3.1 in ./.local/lib/python3.8/site-packages (from accelerate) (0.4.2)\n",
      "Requirement already satisfied: pyparsing>=2.0.2 in /shared/centos7/anaconda3/2021.05/lib/python3.8/site-packages (from packaging>=20.0->accelerate) (2.4.7)\n",
      "Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in ./.local/lib/python3.8/site-packages (from torch>=1.10.0->accelerate) (12.1.3.1)\n",
      "Requirement already satisfied: jinja2 in /shared/centos7/anaconda3/2021.05/lib/python3.8/site-packages (from torch>=1.10.0->accelerate) (2.11.3)\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in ./.local/lib/python3.8/site-packages (from torch>=1.10.0->accelerate) (4.11.0)\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.19.3 in ./.local/lib/python3.8/site-packages (from torch>=1.10.0->accelerate) (2.19.3)\n",
      "Requirement already satisfied: fsspec in ./.local/lib/python3.8/site-packages (from torch>=1.10.0->accelerate) (2024.2.0)\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in ./.local/lib/python3.8/site-packages (from torch>=1.10.0->accelerate) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cudnn-cu12==8.9.2.26 in ./.local/lib/python3.8/site-packages (from torch>=1.10.0->accelerate) (8.9.2.26)\n",
      "Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in ./.local/lib/python3.8/site-packages (from torch>=1.10.0->accelerate) (11.0.2.54)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in ./.local/lib/python3.8/site-packages (from torch>=1.10.0->accelerate) (12.1.105)\n",
      "Requirement already satisfied: networkx in /shared/centos7/anaconda3/2021.05/lib/python3.8/site-packages (from torch>=1.10.0->accelerate) (2.5)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in ./.local/lib/python3.8/site-packages (from torch>=1.10.0->accelerate) (12.1.105)\n",
      "Requirement already satisfied: sympy in /shared/centos7/anaconda3/2021.05/lib/python3.8/site-packages (from torch>=1.10.0->accelerate) (1.8)\n",
      "Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in ./.local/lib/python3.8/site-packages (from torch>=1.10.0->accelerate) (10.3.2.106)\n",
      "Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in ./.local/lib/python3.8/site-packages (from torch>=1.10.0->accelerate) (12.1.0.106)\n",
      "Requirement already satisfied: triton==2.2.0 in ./.local/lib/python3.8/site-packages (from torch>=1.10.0->accelerate) (2.2.0)\n",
      "Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in ./.local/lib/python3.8/site-packages (from torch>=1.10.0->accelerate) (11.4.5.107)\n",
      "Requirement already satisfied: filelock in /shared/centos7/anaconda3/2021.05/lib/python3.8/site-packages (from torch>=1.10.0->accelerate) (3.0.12)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in ./.local/lib/python3.8/site-packages (from torch>=1.10.0->accelerate) (12.1.105)\n",
      "Requirement already satisfied: nvidia-nvjitlink-cu12 in ./.local/lib/python3.8/site-packages (from nvidia-cusolver-cu12==11.4.5.107->torch>=1.10.0->accelerate) (12.4.127)\n",
      "Requirement already satisfied: tqdm>=4.42.1 in ./.local/lib/python3.8/site-packages (from huggingface-hub->accelerate) (4.66.2)\n",
      "Requirement already satisfied: requests in /shared/centos7/anaconda3/2021.05/lib/python3.8/site-packages (from huggingface-hub->accelerate) (2.25.1)\n",
      "Requirement already satisfied: MarkupSafe>=0.23 in /shared/centos7/anaconda3/2021.05/lib/python3.8/site-packages (from jinja2->torch>=1.10.0->accelerate) (1.1.1)\n",
      "Requirement already satisfied: decorator>=4.3.0 in /shared/centos7/anaconda3/2021.05/lib/python3.8/site-packages (from networkx->torch>=1.10.0->accelerate) (5.0.6)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /shared/centos7/anaconda3/2021.05/lib/python3.8/site-packages (from requests->huggingface-hub->accelerate) (2020.12.5)\n",
      "Requirement already satisfied: chardet<5,>=3.0.2 in /shared/centos7/anaconda3/2021.05/lib/python3.8/site-packages (from requests->huggingface-hub->accelerate) (4.0.0)\n",
      "Requirement already satisfied: idna<3,>=2.5 in /shared/centos7/anaconda3/2021.05/lib/python3.8/site-packages (from requests->huggingface-hub->accelerate) (2.10)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /shared/centos7/anaconda3/2021.05/lib/python3.8/site-packages (from requests->huggingface-hub->accelerate) (1.26.4)\n",
      "Requirement already satisfied: mpmath>=0.19 in /shared/centos7/anaconda3/2021.05/lib/python3.8/site-packages (from sympy->torch>=1.10.0->accelerate) (1.2.1)\n",
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: evaluate in ./.local/lib/python3.8/site-packages (0.4.1)\n",
      "Requirement already satisfied: pandas in /shared/centos7/anaconda3/2021.05/lib/python3.8/site-packages (from evaluate) (1.2.4)\n",
      "Requirement already satisfied: datasets>=2.0.0 in ./.local/lib/python3.8/site-packages (from evaluate) (2.18.0)\n",
      "Requirement already satisfied: tqdm>=4.62.1 in ./.local/lib/python3.8/site-packages (from evaluate) (4.66.2)\n",
      "Requirement already satisfied: dill in ./.local/lib/python3.8/site-packages (from evaluate) (0.3.8)\n",
      "Requirement already satisfied: fsspec[http]>=2021.05.0 in ./.local/lib/python3.8/site-packages (from evaluate) (2024.2.0)\n",
      "Requirement already satisfied: numpy>=1.17 in /shared/centos7/anaconda3/2021.05/lib/python3.8/site-packages (from evaluate) (1.20.1)\n",
      "Requirement already satisfied: packaging in /shared/centos7/anaconda3/2021.05/lib/python3.8/site-packages (from evaluate) (20.9)\n",
      "Requirement already satisfied: multiprocess in ./.local/lib/python3.8/site-packages (from evaluate) (0.70.16)\n",
      "Requirement already satisfied: requests>=2.19.0 in /shared/centos7/anaconda3/2021.05/lib/python3.8/site-packages (from evaluate) (2.25.1)\n",
      "Requirement already satisfied: responses<0.19 in ./.local/lib/python3.8/site-packages (from evaluate) (0.18.0)\n",
      "Requirement already satisfied: xxhash in ./.local/lib/python3.8/site-packages (from evaluate) (3.4.1)\n",
      "Requirement already satisfied: huggingface-hub>=0.7.0 in ./.local/lib/python3.8/site-packages (from evaluate) (0.22.2)\n",
      "Requirement already satisfied: filelock in /shared/centos7/anaconda3/2021.05/lib/python3.8/site-packages (from datasets>=2.0.0->evaluate) (3.0.12)\n",
      "Requirement already satisfied: pyarrow-hotfix in ./.local/lib/python3.8/site-packages (from datasets>=2.0.0->evaluate) (0.6)\n",
      "Requirement already satisfied: aiohttp in ./.local/lib/python3.8/site-packages (from datasets>=2.0.0->evaluate) (3.9.3)\n",
      "Requirement already satisfied: pyarrow>=12.0.0 in ./.local/lib/python3.8/site-packages (from datasets>=2.0.0->evaluate) (15.0.2)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /shared/centos7/anaconda3/2021.05/lib/python3.8/site-packages (from datasets>=2.0.0->evaluate) (5.4.1)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in ./.local/lib/python3.8/site-packages (from aiohttp->datasets>=2.0.0->evaluate) (6.0.5)\n",
      "Requirement already satisfied: async-timeout<5.0,>=4.0 in ./.local/lib/python3.8/site-packages (from aiohttp->datasets>=2.0.0->evaluate) (4.0.3)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in ./.local/lib/python3.8/site-packages (from aiohttp->datasets>=2.0.0->evaluate) (1.4.1)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /shared/centos7/anaconda3/2021.05/lib/python3.8/site-packages (from aiohttp->datasets>=2.0.0->evaluate) (20.3.0)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in ./.local/lib/python3.8/site-packages (from aiohttp->datasets>=2.0.0->evaluate) (1.9.4)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in ./.local/lib/python3.8/site-packages (from aiohttp->datasets>=2.0.0->evaluate) (1.3.1)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in ./.local/lib/python3.8/site-packages (from huggingface-hub>=0.7.0->evaluate) (4.11.0)\n",
      "Requirement already satisfied: pyparsing>=2.0.2 in /shared/centos7/anaconda3/2021.05/lib/python3.8/site-packages (from packaging->evaluate) (2.4.7)\n",
      "Requirement already satisfied: idna<3,>=2.5 in /shared/centos7/anaconda3/2021.05/lib/python3.8/site-packages (from requests>=2.19.0->evaluate) (2.10)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /shared/centos7/anaconda3/2021.05/lib/python3.8/site-packages (from requests>=2.19.0->evaluate) (1.26.4)\n",
      "Requirement already satisfied: chardet<5,>=3.0.2 in /shared/centos7/anaconda3/2021.05/lib/python3.8/site-packages (from requests>=2.19.0->evaluate) (4.0.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /shared/centos7/anaconda3/2021.05/lib/python3.8/site-packages (from requests>=2.19.0->evaluate) (2020.12.5)\n",
      "Requirement already satisfied: python-dateutil>=2.7.3 in /shared/centos7/anaconda3/2021.05/lib/python3.8/site-packages (from pandas->evaluate) (2.8.1)\n",
      "Requirement already satisfied: pytz>=2017.3 in /shared/centos7/anaconda3/2021.05/lib/python3.8/site-packages (from pandas->evaluate) (2021.1)\n",
      "Requirement already satisfied: six>=1.5 in /shared/centos7/anaconda3/2021.05/lib/python3.8/site-packages (from python-dateutil>=2.7.3->pandas->evaluate) (1.15.0)\n",
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: sentencepiece in ./.local/lib/python3.8/site-packages (0.2.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install datasets\n",
    "!pip install accelerate -U\n",
    "!pip install evaluate\n",
    "!pip install sentencepiece"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "367ab053-93e9-4fdb-aff7-f9e57101d8c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from datasets import Dataset, DatasetDict\n",
    "\n",
    "### give your file path\n",
    "dataset_path = \"train_v2_drcat_02.csv\"\n",
    "df = pd.read_csv(dataset_path, header = 0)\n",
    "\n",
    "### get the labels\n",
    "label = df['label']\n",
    "label = label.astype(\"int\")\n",
    "# df.drop(columns='label', axis = 1, inplace = True)\n",
    "df.drop(columns='RDizzl3_seven', axis = 1, inplace=True)\n",
    "df.drop(columns='prompt_name', axis = 1, inplace=True)\n",
    "df.drop(columns='source', axis = 1, inplace=True)\n",
    "df.dropna(subset=['text'], inplace=True)\n",
    "\n",
    "train_df, test_df = train_test_split(df, test_size=0.2, random_state=42, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1f0eb7e6-db16-4c88-9bfc-6418465dcbfc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: transformers in ./.local/lib/python3.8/site-packages (4.39.3)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.19.3 in ./.local/lib/python3.8/site-packages (from transformers) (0.22.2)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /shared/centos7/anaconda3/2021.05/lib/python3.8/site-packages (from transformers) (5.4.1)\n",
      "Requirement already satisfied: requests in /shared/centos7/anaconda3/2021.05/lib/python3.8/site-packages (from transformers) (2.25.1)\n",
      "Requirement already satisfied: packaging>=20.0 in /shared/centos7/anaconda3/2021.05/lib/python3.8/site-packages (from transformers) (20.9)\n",
      "Requirement already satisfied: filelock in /shared/centos7/anaconda3/2021.05/lib/python3.8/site-packages (from transformers) (3.0.12)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /shared/centos7/anaconda3/2021.05/lib/python3.8/site-packages (from transformers) (2021.4.4)\n",
      "Requirement already satisfied: numpy>=1.17 in /shared/centos7/anaconda3/2021.05/lib/python3.8/site-packages (from transformers) (1.20.1)\n",
      "Requirement already satisfied: tokenizers<0.19,>=0.14 in ./.local/lib/python3.8/site-packages (from transformers) (0.15.2)\n",
      "Requirement already satisfied: tqdm>=4.27 in ./.local/lib/python3.8/site-packages (from transformers) (4.66.2)\n",
      "Requirement already satisfied: safetensors>=0.4.1 in ./.local/lib/python3.8/site-packages (from transformers) (0.4.2)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in ./.local/lib/python3.8/site-packages (from huggingface-hub<1.0,>=0.19.3->transformers) (2024.2.0)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in ./.local/lib/python3.8/site-packages (from huggingface-hub<1.0,>=0.19.3->transformers) (4.11.0)\n",
      "Requirement already satisfied: pyparsing>=2.0.2 in /shared/centos7/anaconda3/2021.05/lib/python3.8/site-packages (from packaging>=20.0->transformers) (2.4.7)\n",
      "Requirement already satisfied: idna<3,>=2.5 in /shared/centos7/anaconda3/2021.05/lib/python3.8/site-packages (from requests->transformers) (2.10)\n",
      "Requirement already satisfied: chardet<5,>=3.0.2 in /shared/centos7/anaconda3/2021.05/lib/python3.8/site-packages (from requests->transformers) (4.0.0)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /shared/centos7/anaconda3/2021.05/lib/python3.8/site-packages (from requests->transformers) (1.26.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /shared/centos7/anaconda3/2021.05/lib/python3.8/site-packages (from requests->transformers) (2020.12.5)\n",
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: protobuf in ./.local/lib/python3.8/site-packages (5.26.1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of DebertaV2ForSequenceClassification were not initialized from the model checkpoint at microsoft/deberta-v3-xsmall and are newly initialized: ['classifier.bias', 'classifier.weight', 'pooler.dense.bias', 'pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "!pip install transformers\n",
    "!pip install protobuf\n",
    "from transformers import AutoTokenizer, DebertaV2Tokenizer, DebertaV2ForSequenceClassification\n",
    "import torch\n",
    "import gc\n",
    "gc.collect()\n",
    "torch.cuda.empty_cache()\n",
    "\n",
    "### testing\n",
    "# model = DebertaV2ForSequenceClassification.from_pretrained(\"microsoft/deberta-v3-small\", num_labels = 2)\n",
    "# tokenizer = DebertaV2Tokenizer.from_pretrained(\"microsoft/deberta-v3-small\")\n",
    "model = DebertaV2ForSequenceClassification.from_pretrained(\"microsoft/deberta-v3-xsmall\", num_labels = 2)\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"microsoft/deberta-v3-xsmall\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "69cf4ed8-bf04-43c1-bcec-084031eaa0a1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ebc930ee55664f0f8acaf8453da8ee24",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/35894 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Asking to pad to max_length but no maximum length is provided and the model has no predefined maximum length. Default to no padding.\n",
      "Asking to truncate to max_length but no maximum length is provided and the model has no predefined maximum length. Default to no truncation.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bd26d40da07547a5ae4ba71c0dc268a5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/8974 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset({\n",
      "    features: ['label', 'input_ids', 'attention_mask'],\n",
      "    num_rows: 35894\n",
      "})\n",
      "Dataset({\n",
      "    features: ['label', 'input_ids', 'attention_mask'],\n",
      "    num_rows: 8974\n",
      "})\n"
     ]
    }
   ],
   "source": [
    "def tokenize_func(dataset):\n",
    "    return tokenizer(list(dataset['text']), padding = \"max_length\", truncation = True)\n",
    "\n",
    "train_dataset = Dataset.from_pandas(train_df)\n",
    "test_dataset = Dataset.from_pandas(test_df)\n",
    "\n",
    "train_tokenized_datasets = train_dataset.map(tokenize_func, batched = True)\n",
    "test_tokenized_datasets = test_dataset.map(tokenize_func, batched = True)\n",
    "train_tokenized_datasets.set_format(type='torch', columns = ['input_ids', 'attention_mask', 'label'])\n",
    "test_tokenized_datasets.set_format(type='torch', columns = ['input_ids', 'attention_mask', 'label'])\n",
    "\n",
    "# Drop columns from the tokenized datasets\n",
    "columns_to_drop = [\"text\", \"__index_level_0__\", \"token_type_ids\"]  # Specify columns to drop\n",
    "train_tokenized_datasets = train_tokenized_datasets.remove_columns(columns_to_drop)\n",
    "test_tokenized_datasets = test_tokenized_datasets.remove_columns(columns_to_drop)\n",
    "\n",
    "print(train_tokenized_datasets)\n",
    "print(test_tokenized_datasets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1fb2b159-9ee9-460e-80bb-3ca6dfae07a1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "63d2c6682b10454b8c0aca383fba1f1b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading builder script:   0%|          | 0.00/4.20k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from transformers import Trainer, TrainingArguments\n",
    "import evaluate\n",
    "import torch.nn.functional as F\n",
    "\n",
    "batch_size = 2\n",
    "args = TrainingArguments(output_dir = \"LLMvHuman_finetune\",\n",
    "                               num_train_epochs = 2,\n",
    "                               learning_rate = 2e-5,\n",
    "                               per_device_train_batch_size = batch_size,\n",
    "                               per_device_eval_batch_size = batch_size,\n",
    "                               weight_decay = 0.01,\n",
    "                               evaluation_strategy = \"epoch\",\n",
    "                               disable_tqdm = False,\n",
    "                               logging_steps = 10000,\n",
    "                               push_to_hub = False,\n",
    "                              #  log_level = \"error\",\n",
    "                               save_strategy=\"epoch\",\n",
    "                               load_best_model_at_end=True\n",
    "                              #  fp16=True,\n",
    "                              #  fp16_backend=\"auto\"\n",
    "                              )\n",
    "metric = evaluate.load('accuracy')\n",
    "\n",
    "def compute_metrics(eval_pred):\n",
    "    logits, labels = eval_pred\n",
    "    predictions = np.argmax(logits, axis=-1)\n",
    "    return metric.compute(predictions=predictions, references=labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "0e089979-7582-4a7b-975a-71fa7778fa29",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mohbe.r/.local/lib/python3.8/site-packages/accelerate/accelerator.py:436: FutureWarning: Passing the following arguments to `Accelerator` is deprecated and will be removed in version 1.0 of Accelerate: dict_keys(['dispatch_batches', 'split_batches', 'even_batches', 'use_seedable_sampler']). Please pass an `accelerate.DataLoaderConfiguration` instead: \n",
      "dataloader_config = DataLoaderConfiguration(dispatch_batches=None, split_batches=False, even_batches=True, use_seedable_sampler=True)\n",
      "  warnings.warn(\n",
      "Detected kernel version 3.10.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='35894' max='35894' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [35894/35894 1:25:13, Epoch 2/2]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.056000</td>\n",
       "      <td>0.023763</td>\n",
       "      <td>0.997103</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.011600</td>\n",
       "      <td>0.029310</td>\n",
       "      <td>0.996323</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='4487' max='4487' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [4487/4487 01:39]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "{'eval_loss': 0.02376273274421692,\n",
       " 'eval_accuracy': 0.9971027412525072,\n",
       " 'eval_runtime': 99.2751,\n",
       " 'eval_samples_per_second': 90.395,\n",
       " 'eval_steps_per_second': 45.198,\n",
       " 'epoch': 2.0}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cuda.empty_cache()\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model,                         # the instantiated Transformers model to be trained\n",
    "    args=args,                  # training arguments, defined above\n",
    "    train_dataset=train_tokenized_datasets,         # training dataset\n",
    "    eval_dataset=test_tokenized_datasets,             # evaluation dataset\n",
    "    tokenizer = tokenizer,\n",
    "    # use_amp=True,\n",
    "    compute_metrics = compute_metrics\n",
    ")\n",
    "\n",
    "# Step 8: Train the model\n",
    "trainer.train()\n",
    "\n",
    "# Step 9: Evaluate the model\n",
    "trainer.evaluate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "21e595e8-e8c1-4d1d-9174-5daad1f27b4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save_pretrained(\"./model\", from_pt=True) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "4e78d84a-0675-401c-aa9f-fca9959fd461",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('./model/tokenizer_config.json',\n",
       " './model/special_tokens_map.json',\n",
       " './model/spm.model',\n",
       " './model/added_tokens.json',\n",
       " './model/tokenizer.json')"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.save_pretrained(\"./model\" )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "247aa0a2-9416-44dc-9930-f9bb9bac36b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.save_model(\"./my_model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "dc9a864c-1f5d-4b96-a0b8-22446e10c21e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted class label: 0\n",
      "Predicted class probabilities: tensor([[9.9999e-01, 1.4389e-05]])\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoTokenizer, DebertaV2Tokenizer, DebertaV2ForSequenceClassification\n",
    "import torch\n",
    "import gc\n",
    "gc.collect()\n",
    "torch.cuda.empty_cache()\n",
    "\n",
    "# ### testing\n",
    "# # model = DebertaV2ForSequenceClassification.from_pretrained(\"microsoft/deberta-v3-small\", num_labels = 2)\n",
    "# # tokenizer = DebertaV2Tokenizer.from_pretrained(\"microsoft/deberta-v3-small\")\n",
    "# model = DebertaV2ForSequenceClassification.from_pretrained(\"microsoft/deberta-v3-xsmall\", num_labels = 2)\n",
    "# tokenizer = AutoTokenizer.from_pretrained(\"microsoft/deberta-v3-xsmall\")\n",
    "\n",
    "\n",
    "\n",
    "# Load the fine-tuned model\n",
    "model_path = \"./my_model\"  # Specify the path to your fine-tuned model\n",
    "model = DebertaV2ForSequenceClassification.from_pretrained(model_path)\n",
    "\n",
    "# Load the tokenizer\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_path)\n",
    "\n",
    "# Example text for prediction\n",
    "text = \"Essay written by human. Will my model classify this correctly? I am a bit skeptical. See the word embeddings are positional encodings. Idk what else the model will learn apart from context w.r.t the content. Have to see!\"\n",
    "# text = \"fuck yes.....this is human\"\n",
    "# text = \"In the era of advancing technology, the emergence of Large Language Models (LLMs) like GPT has stirred debates on the potential rivalry between artificial and human intelligence.  LLMs, powered by vast datasets and complex algorithms, exhibit remarkable linguistic abilities. However, they lack the nuanced understanding, consciousness, and emotional depth inherent in human intelligence.  Despite disparities, LLMs and humans can collaborate effectively. LLMs excel in data processing, while humans contribute contextual understanding and ethical judgment. Ethical concerns, including privacy and algorithmic bias, necessitate careful regulation and oversight. Furthermore, societal implications such as job displacement and inequality must be addressed.  In conclusion, while LLMs offer significant potential, their integration should be approached with caution. Collaborative efforts can ensure that AI enhances, rather than undermines, human well-being and autonomy.\"\"\"\n",
    "# Tokenize input text\n",
    "inputs = tokenizer(text, return_tensors=\"pt\")\n",
    "\n",
    "# Perform inference\n",
    "with torch.no_grad():\n",
    "    outputs = model(**inputs)\n",
    "\n",
    "# Get predicted class probabilities\n",
    "probs = torch.softmax(outputs.logits, dim=-1)\n",
    "\n",
    "# Get predicted class label\n",
    "predicted_class = torch.argmax(probs, dim=-1).item()\n",
    "\n",
    "print(\"Predicted class label:\", predicted_class) #it needs to print 0\n",
    "print(\"Predicted class probabilities:\", probs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b3eafde-90f1-4683-b167-aec43426fe7e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
